{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running locally\n"
     ]
    }
   ],
   "source": [
    "import getopt\n",
    "import sys\n",
    "\n",
    "if '-i' in sys.argv:\n",
    "    myopts, args = getopt.getopt(sys.argv[1:],\"i:c:\")\n",
    "\n",
    "    for o, a in myopts:\n",
    "        if o == '-i':\n",
    "            i=int(a)\n",
    "        elif o == '-c':\n",
    "            n_cores=int(a)\n",
    "        else:\n",
    "            print(\"Usage: %s -i iteration -n_cores n_cores\" % sys.argv[0])\n",
    "\n",
    "    # Display input and output file name passed as the args\n",
    "    print (\"Running: %d with n_cores: %d\" % (i, n_cores) )\n",
    "else:\n",
    "    i = 0\n",
    "    n_cores=11\n",
    "    print('Running locally')\n",
    "\n",
    "# set theano flags\n",
    "import os\n",
    "os.environ[\"THEANO_FLAGS\"] = \"compiledir=./theano/%s/\" %(str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for smooth switch point:\n",
    "# https://gist.github.com/junpenglao/f7098c8e0d6eadc61b3e1bc8525dd90d\n",
    "import theano.tensor as tt\n",
    "from pymc3.distributions.transforms import ElemwiseTransform, Transform\n",
    "\n",
    "class Ordered(ElemwiseTransform):\n",
    "    name = \"ordered\"\n",
    "\n",
    "    def backward(self, y):\n",
    "        out = tt.zeros(y.shape)\n",
    "        out = tt.inc_subtensor(out[0], y[0])\n",
    "        out = tt.inc_subtensor(out[1:], tt.exp(y[1:]))\n",
    "        return tt.cumsum(out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = tt.zeros(x.shape)\n",
    "        out = tt.inc_subtensor(out[0], x[0])\n",
    "        out = tt.inc_subtensor(out[1:], tt.log(x[1:] - x[:-1]))\n",
    "        return out\n",
    "\n",
    "    def forward_val(self, x, point=None):\n",
    "        x, = draw_values([x], point=point)\n",
    "        return self.forward(x)\n",
    "\n",
    "    def jacobian_det(self, y):\n",
    "        return tt.sum(y[1:])\n",
    "\n",
    "ordered = Ordered()\n",
    "\n",
    "\n",
    "class Composed(Transform):\n",
    "    def __init__(self, transform1, transform2):\n",
    "        self._transform1 = transform1\n",
    "        self._transform2 = transform2\n",
    "        self.name = '_'.join([transform1.name, transform2.name])\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._transform2.forward(self._transform1.forward(x))\n",
    "\n",
    "    def forward_val(self, x, point=None):\n",
    "        return self.forward(x)\n",
    "\n",
    "    def backward(self, y):\n",
    "        return self._transform1.backward(self._transform2.backward(y))\n",
    "\n",
    "    def jacobian_det(self, y):\n",
    "        y2 = self._transform2.backward(y)\n",
    "        det1 = self._transform1.jacobian_det(y2)\n",
    "        det2 = self._transform2.jacobian_det(y)\n",
    "        return det1 + det2\n",
    "    \n",
    "def logistic(L, x0, k=50, t_=np.linspace(0., 1., 1000)):\n",
    "    x0 = x0*(t_.max()-t_.min()) + t_.min()  # scale x0 to t_\n",
    "    return L/(1+tt.exp(-k*(t_-x0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_single_model(df, model_n, distribution, dep_var='rate', n_cores=15):\n",
    "\n",
    "    with pm.Model() as model:\n",
    "        mu = np.log(df[dep_var].mean())\n",
    "        sd = np.log(df[dep_var].std())\n",
    "        tune_steps = 500\n",
    "        init = 'jitter+adapt_diag'\n",
    "\n",
    "        if model_n == 1:\n",
    "            # no change\n",
    "            intercept = pm.Normal('intercept', mu=mu, sd=sd)\n",
    "            ev = np.exp(intercept)\n",
    "\n",
    "        elif model_n == 2:\n",
    "            # gradient along pc axis 1\n",
    "            intercept = pm.Normal('intercept', mu=mu, sd=sd)\n",
    "            beta_pca_1 = pm.Normal('beta_pca_1', mu=0, sd=3)\n",
    "            ev = np.exp(intercept + beta_pca_1*df['pc1_mm_norm'].values)\n",
    "\n",
    "        elif model_n == 3:\n",
    "            intercept = pm.Normal('intercept', mu=mu, sd=sd)\n",
    "            # 3 sectors along pc axis 1\n",
    "            delta_center_1 = pm.Normal('delta_center_1', mu=0, sd=3)\n",
    "            delta_center_3 = pm.Normal('delta_center_3', mu=0, sd=3)\n",
    "\n",
    "            ev = np.exp(intercept + \\\n",
    "                        delta_center_1*((df['pc1_mm_perc'].values<0.333).astype(int)) + \\\n",
    "                        delta_center_3*((df['pc1_mm_perc'].values>0.667).astype(int)))\n",
    "\n",
    "        elif model_n == 4:\n",
    "            intercept = pm.Normal('intercept', mu=mu, sd=sd)\n",
    "            # gradient along pc axis 1+2+3\n",
    "            beta_pca_1 = pm.Normal('beta_pca_1', mu=0, sd=3)\n",
    "            beta_pca_2 = pm.Normal('beta_pca_2', mu=0, sd=3)\n",
    "            beta_slice = pm.Normal('beta_slice', mu=0, sd=3)\n",
    "\n",
    "            ev = tt.exp(intercept + beta_pca_1*df['pc1_mm_norm'].values + \\\n",
    "                        beta_pca_2*df['pc2_mm_norm'].values + \\\n",
    "                        beta_slice*df['slice_mm_norm'].values)\n",
    "\n",
    "#         elif model_n == 5:\n",
    "#             # cut-offs estimated, smoothness of cut-off estimated\n",
    "#             nbreak = 3\n",
    "#             lambdad = pm.Normal('lambdad', 0, sd=1, shape=3-1)\n",
    "#             k = pm.HalfNormal('k', 20)  # always assume positive\n",
    "#             trafo = Composed(pm.distributions.transforms.LogOdds(), Ordered())\n",
    "#             b = pm.Beta('b', 4., 4., shape=nbreak-1, transform=trafo,\n",
    "#                         testval=[0.33, 0.67])\n",
    "#             ev = np.exp(intercept + logistic(lambdad[0], b[0], k=-k, t_=df['pc1_mm_norm'].values) +\n",
    "#                                     logistic(lambdad[1], b[1], k=k, t_=df['pc1_mm_norm'].values))\n",
    "#             tune_steps = 1500\n",
    "            \n",
    "        elif model_n == 6:\n",
    "            # cut-offs estimated in 3D, smoothness of cut-off estimated\n",
    "            beta_pca_1 = pm.HalfCauchy('beta_pca_1', 1)\n",
    "            beta_pca_2 = pm.HalfCauchy('beta_pca_2', 1)\n",
    "            beta_slice = pm.HalfCauchy('beta_slice', 1)\n",
    "            \n",
    "            k = pm.Laplace('smoothness', 500, 5) #pm.TruncatedNormal('smoothness', mu=100, sd=10, lower=0)\n",
    "            trafo = Composed(pm.distributions.transforms.LogOdds(), Ordered())\n",
    "#             lambdad = pm.Normal('lambdad', 0, sd, shape=3-1)\n",
    "            lambda0 = pm.Normal('lambda0', mu=mu, sd=sd, shape=1)\n",
    "            lambdas = pm.Normal('lambdas', mu=0, sd=sd, shape=2)\n",
    "    \n",
    "            b = pm.Beta('b', 4., 4., shape=2, transform=trafo, testval=[0.33, 0.67])\n",
    "\n",
    "            # projection on new axis\n",
    "#            beta_slice = pm.Deterministic('beta_slice', np.sqrt(1**2-beta_pca_1**2-beta_pca_2**2))\n",
    "            O_vec = beta_pca_1*df['pc1_mm_norm'].values + \\\n",
    "                    beta_pca_2*df['pc2_mm_norm'].values + \\\n",
    "                    beta_slice*df['slice_mm_norm'].values\n",
    "            # standardize new axis\n",
    "            O_vec = (O_vec-O_vec.mean())/(O_vec.std())\n",
    "            \n",
    "#             ev = tt.exp(intercept + logistic(lambdad[0], b[0], k=k, t_=O_vec) +\n",
    "#                                     logistic(lambdad[1]-lambdad[0], b[1], k=k, t_=O_vec))\n",
    "            ev = tt.exp(lambda0 + \\\n",
    "                        logistic(lambdas[0], b[1], k=k, t_=O_vec) + \\\n",
    "                        logistic(lambdas[1]-lambdas[0], b[1], k=k, t_=O_vec))\n",
    "                        \n",
    "#                         lambdas[0]/(1+tt.exp(-k*(b[0]-t_))) + \\\n",
    "#                         lambdas[1]/(1+tt.exp(-k*(t_-b[0]))) + \\\n",
    "#                         (lambdas[2]-lambdas[1])/(1+tt.exp(-k*(t_-b[1])))))  # intercept section 3\n",
    "            tune_steps = 500\n",
    "            \n",
    "#         elif model_n == 7:\n",
    "#             # cut-offs estimated in 3D, smoothness of cut-off estimated\n",
    "#             beta_pca_1 = pm.HalfNormal('beta_pca_1', sd=3)\n",
    "#             beta_pca_2 = pm.HalfNormal('beta_pca_2', sd=3)\n",
    "#             beta_slice = pm.HalfNormal('beta_slice', sd=3)\n",
    "#             k = pm.HalfNormal('smoothness', sd=3)\n",
    "#             trafo = Composed(pm.distributions.transforms.LogOdds(), Ordered())\n",
    "#             b = pm.Beta('b', 4., 4., shape=2, transform=trafo, testval=[0.33, 0.67])\n",
    "#             lambdad = pm.Normal('lambdad', mu=0, sd=1, shape=3-1)\n",
    "            \n",
    "#             # projection on new axis\n",
    "#             O_vec = beta_pca_1*df['pc2.1'].values + \\\n",
    "#                     beta_pca_2*df['pc2.2'].values + \\\n",
    "#                     beta_slice*df['pc2.3'].values\n",
    "#             # standardize new axis\n",
    "#             O_vec = (O_vec-O_vec.mean())/(O_vec.std())\n",
    "        \n",
    "#             ev = np.exp(intercept + intercept*logistic(lambdad[0], b[0], k=k, t_=O_vec) +\n",
    "#                                     intercept*logistic(lambdad[1], b[1], k=k, t_=O_vec))\n",
    "#             tune_steps = 500\n",
    "\n",
    "        # define likelihood\n",
    "        if distribution == 'poisson':\n",
    "            likelihood = pm.Poisson('y', mu=ev, observed=df[dep_var])\n",
    "        else:\n",
    "            alpha = pm.HalfCauchy('alpha', beta=2)\n",
    "            likelihood = pm.NegativeBinomial('y', mu=ev, alpha=alpha, observed=df[dep_var])\n",
    "\n",
    "        model.name = str(model_n) + '_' + distribution\n",
    "        traces = pm.sample(cores=n_cores, tune=tune_steps, init=init)\n",
    "        \n",
    "        return model, traces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.read_pickle('./data_fwhm-0.3.pkl')\n",
    "subjects = df.subject_id.unique()\n",
    "stains = df.stain.unique()\n",
    "models = [6,4,3,2,1]\n",
    "distributions = ['poisson']#, 'negativebinomial']\n",
    "\n",
    "output_dir = './models_local_advi_adapt'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "all_combs = list(itertools.product(subjects, stains))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 13095, stain CALR, model 6, distribution poisson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi+adapt_diag...\n",
      "Average Loss = 10,971:  11%|█         | 22494/200000 [01:10<08:58, 329.77it/s]\n",
      "Convergence achieved at 22500\n",
      "Interrupted at 22,499 [11%]: Average Loss = 13,476\n",
      "Multiprocess sampling (11 chains in 11 jobs)\n",
      "NUTS: [b_logodds, lambdas, lambda0, smoothness, beta_slice, beta_pca_2, beta_pca_1]\n",
      "Sampling 11 chains:  94%|█████████▍| 10377/11000 [36:24<04:01,  2.58draws/s] \n",
      "There were 6 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.04172245731169198, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The acceptance probability does not match the target. It is 0.5399983292181264, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The chain reached the maximum tree depth. Increase max_treedepth, increase target_accept or reparameterize.\n",
      "There were 2 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.6008474264255464, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The chain reached the maximum tree depth. Increase max_treedepth, increase target_accept or reparameterize.\n",
      "The gelman-rubin statistic is larger than 1.4 for some parameters. The sampler did not converge.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 13095, stain CALR, model 4, distribution poisson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (11 chains in 11 jobs)\n",
      "NUTS: [beta_slice, beta_pca_2, beta_pca_1, intercept]\n",
      "Process worker_chain_8:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 251, in _bootstrap\n",
      "    util._run_after_forkers()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/util.py\", line 128, in _run_after_forkers\n",
      "    items = list(_afterfork_registry.items())\n",
      "  File \"/opt/conda/lib/python3.6/weakref.py\", line 209, in items\n",
      "    if self._pending_removals:\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-1c19e8b1b9f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_single_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_to_run\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistribution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_cores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0mpkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-6a236dfa924c>\u001b[0m in \u001b[0;36msample_single_model\u001b[0;34m(df, model_n, distribution, dep_var, n_cores)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_n\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdistribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mtraces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_cores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtune\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtune_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraces\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pymc3/sampling.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(draws, step, init, n_init, start, trace, chain_idx, chains, cores, tune, nuts_kwargs, step_kwargs, progressbar, model, random_seed, live_plot, discard_tuned_samples, live_plot_kwargs, compute_convergence_checks, use_mmap, **kwargs)\u001b[0m\n\u001b[1;32m    437\u001b[0m             \u001b[0m_print_step_hierarchy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_mp_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0msample_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPickleError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0m_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Could not pickle model, sampling singlethreaded.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pymc3/sampling.py\u001b[0m in \u001b[0;36m_mp_sample\u001b[0;34m(draws, tune, step, chains, cores, chain, random_seed, start, progressbar, trace, model, use_mmap, **kwargs)\u001b[0m\n\u001b[1;32m    984\u001b[0m         sampler = ps.ParallelSampler(\n\u001b[1;32m    985\u001b[0m             \u001b[0mdraws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtune\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchains\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m             chain, progressbar)\n\u001b[0m\u001b[1;32m    987\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pymc3/parallel_sampling.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, draws, tune, chains, cores, seeds, start_points, step_method, start_chain_num, progressbar)\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0mdraws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtune\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchain\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstart_chain_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m             )\n\u001b[0;32m--> 313\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchains\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m         ]\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pymc3/parallel_sampling.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0mdraws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtune\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchain\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstart_chain_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m             )\n\u001b[0;32m--> 313\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchains\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m         ]\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pymc3/parallel_sampling.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, draws, tune, step_method, chain, seed, start)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Variable %s is too large\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msharedctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRawArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shared_point\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0marray_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/multiprocessing/sharedctypes.py\u001b[0m in \u001b[0;36mRawArray\u001b[0;34m(typecode_or_type, size_or_initializer)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_or_initializer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mtype_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msize_or_initializer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_new_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddressof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msizeof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/multiprocessing/sharedctypes.py\u001b[0m in \u001b[0;36m_new_value\u001b[0;34m(type_)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msizeof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mwrapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mheap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBufferWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrebuild_ctype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mRawValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtypecode_or_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/multiprocessing/sharedctypes.py\u001b[0m in \u001b[0;36mrebuild_ctype\u001b[0;34m(type_, wrapper, length)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_ctype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_memoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m     \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m     \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in [0,1,2,3,4,5,6,7,8,9,10]:\n",
    "    subject, stain = all_combs[i]\n",
    "    df_to_run = df.loc[(df.subject_id==subject) & (df.stain==stain),:]\n",
    "    \n",
    "    for model_n in models:\n",
    "        for distribution in distributions:\n",
    "            print('Subject {}, stain {}, model {}, distribution {}'.format(subject, stain, model_n, distribution))\n",
    "            trace_fn = os.path.join(output_dir, 'sub-{}_stain-{}_model-{}_distribution-{}_type-traces.pkl').format(subject, stain, model_n, distribution)\n",
    "            model_fn = os.path.join(output_dir, 'sub-{}_stain-{}_model-{}_distribution-{}_type-model.pkl').format(subject, stain, model_n, distribution)\n",
    "            if os.path.exists(trace_fn):\n",
    "                continue\n",
    "\n",
    "            model, traces = sample_single_model(df_to_run, model_n, distribution, n_cores=n_cores)\n",
    "            with open(model_fn, 'wb') as f:\n",
    "                pkl.dump(model, f)\n",
    "            with open(trace_fn, 'wb') as f:\n",
    "                pkl.dump(traces, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(traces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_df = pm.trace_to_dataframe(traces)\n",
    "import seaborn as sns\n",
    "sns.pairplot(trace_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
